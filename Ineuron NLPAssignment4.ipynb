{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd87ce40",
   "metadata": {},
   "source": [
    "1.\tCan you think of a few applications for a sequence-to-sequence RNN? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d83792",
   "metadata": {},
   "source": [
    "Sequence to Sequence (often abbreviated to seq2seq) models is a special class of Recurrent Neural Network architectures that we typically use (but not restricted) to solve complex Language problems like Machine Translation, Question Answering, creating Chatbots, Text Summarization, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68887ae0",
   "metadata": {},
   "source": [
    "2.\tWhy do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6da32",
   "metadata": {},
   "source": [
    "Encoder-decoder architectures have been successful in various NLP tasks, including machine translation, text summarization, dialogue generation, and more. The ability to handle variable-length input and output sequences makes them versatile for tasks involving sequential data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c1aa67",
   "metadata": {},
   "source": [
    "3.\tHow could you combine a convolutional neural network with an RNN to classify videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f37f71",
   "metadata": {},
   "source": [
    "By using a combined CNN-RNN architecture, we can get the best of both worlds. The images of a video are fed to a CNN model to extract high-level features. The features are then fed to an RNN layer and the output of the RNN layer is connected to a fully connected layer to get the classification output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f07e6d0",
   "metadata": {},
   "source": [
    "4.\tWhat are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84331eb",
   "metadata": {},
   "source": [
    "Building an RNN usingdynamic_rnn()rather thanstatic_rnn() offers several advantages: It is based on awhile_loop() operation that is able to swap the GPU’s memory to the CPU’s memory during backpropagation, avoiding out-of-memory errors. It is arguably easier to use, as it can directly take a single tensor as input and output (covering all time steps), rather than a list of tensors (one per time step). No need to stack, unstack, or transpose. It generates a smaller graph, easier to visualize in TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1cd7f1",
   "metadata": {},
   "source": [
    "5.\tHow can you deal with variable-length input sequences? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bee4a2",
   "metadata": {},
   "source": [
    "In general if inputs are from variable lengths you may fix them to a specific size which let's you input all your data. Theoretically that size is the length of longest sequence in your data and any shorter sequence gets some zeros to become as long as the fixed size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30327bb4",
   "metadata": {},
   "source": [
    "6.\tWhat is a common way to distribute training and execution of a deep RNN across multiple GPUs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e28eb6",
   "metadata": {},
   "source": [
    "Once multiple GPUs are added to your systems, you need to build parallelism into your deep learning processes. There are two main methods to add parallelism—models and data. Model parallelism is a method you can use when your parameters are too large for your memory constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2301281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0560b8d9",
   "metadata": {},
   "source": [
    "1.\tWhat are Corpora?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88db011",
   "metadata": {},
   "source": [
    "A corpus is a collection of authentic text or audio organized into datasets. Authentic here means text written or audio spoken by a native of the language or dialect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6968cc",
   "metadata": {},
   "source": [
    "2.\tWhat are Tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbabd3",
   "metadata": {},
   "source": [
    "Tokenization, in the realm of Natural Language Processing (NLP) and machine learning, refers to the process of converting a sequence of text into smaller parts, known as tokens. These tokens can be as small as characters or as long as words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e8a483",
   "metadata": {},
   "source": [
    "3.\tWhat are Unigrams, Bigrams, Trigrams?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ef70a",
   "metadata": {},
   "source": [
    "– A 1-gram (unigram) is a single word sequence of words like “please” or “ turn”. – A 2-gram (bigram) is a two-word sequence of words like “please turn”, “turn your”, or ”your homework”. – A 3-gram (trigram) is a three-word sequence of words like “please turn your”, or “turn your homework”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cf776",
   "metadata": {},
   "source": [
    "4.\tHow to generate n-grams from text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4285b2",
   "metadata": {},
   "source": [
    "N-grams are all possible combinations of “N” words from the text. When two words are combined at a time, they are known as Bigrams, when three words are combined at a time, they are known as Trigrams, so on and so forth. They are very useful when we are trying to do NLP because combinations of words are more meaningful as compared to individual words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07979d62",
   "metadata": {},
   "source": [
    "5.\tExplain Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27954ca",
   "metadata": {},
   "source": [
    "Lemmatization (or less commonly lemmatisation) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6de32",
   "metadata": {},
   "source": [
    "6.\tExplain Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25318aae",
   "metadata": {},
   "source": [
    "Simplifying words to their most basic form is called stemming, and it is made easier by stemmers or stemming algorithms. For example, “chocolates” becomes “chocolate” and “retrieval” becomes “retrieve.” This is crucial for pipelines for natural language processing, which use tokenized words that are acquired from the first stage of dissecting a document into its constituent words.\n",
    "\n",
    "Stemming in natural language processing reduces words to their base or root form, aiding in text normalization for easier processing. This technique is crucial in tasks like text classification, information retrieval, and text summarization. While beneficial, stemming has drawbacks, including potential impacts on text readability and occasional inaccuracies in determining the correct root form of a word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd441d45",
   "metadata": {},
   "source": [
    "7.\tExplain Part-of-speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08723561",
   "metadata": {},
   "source": [
    "In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e4a0d",
   "metadata": {},
   "source": [
    "8.\tExplain Chunking or shallow parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1524b21",
   "metadata": {},
   "source": [
    "Shallow parsing (also chunking or light parsing) is an analysis of a sentence which first identifies constituent parts of sentences (nouns, verbs, adjectives, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178ba1a8",
   "metadata": {},
   "source": [
    "9.\tExplain Noun Phrase (NP) chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19852d2",
   "metadata": {},
   "source": [
    "Phrase chunking is a phase of natural language processing that separates and segments a sentence into its subconstituents, such as noun, verb, and prepositional phrases, abbreviated as NP, VP, and PP, respectively. Typically, each subconstituent or chunk is denoted by brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a845b34",
   "metadata": {},
   "source": [
    "10.\tExplain Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd92b275",
   "metadata": {},
   "source": [
    "Named-entity recognition is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d63c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
